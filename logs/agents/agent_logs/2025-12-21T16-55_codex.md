# Agent Log — RAM OOM Mitigation for 40-Run Sweep

- Agent: Codex CLI
- Model: GPT-5.2
- Created (UTC): 2025-12-21T16:55:45+00:00

## Symptom

The 10% full-grid sweep repeatedly failed on `A4_gap1_foldA` with run dirs missing `metrics.json` (indicating the child process was killed before completing), consistent with RAM OOM.

## Root cause (likely)

`kaggle_clicks/time_agg.py` previously stored a separate per-window deque for each entity key, duplicating per-hour event blocks across windows. A4+gap increases the number of tracked windows and can push peak RAM over the machine limit.

## Changes made

- `kaggle_clicks/time_agg.py`
  - Reworked trailing window state to store per-hour event blocks **once per entity** and compute trailing sums from prefix sums (large memory reduction vs per-window deques).
  - Added `inplace` option and used `pd.concat` to attach all new feature columns at once (avoids fragmentation / peak overhead from many inserts).
- `kaggle_clicks/te.py`
  - Added `inplace` option to avoid a full DataFrame copy when used in the main pipeline.
- `kaggle_clicks/run_baseline_te.py`
  - Uses TE/time-agg in “inplace” mode and drops non-entity categorical columns before time-agg to reduce peak RAM.
- `docs/AGENT_ONBOARDING.md`
  - Added a short “Resource troubleshooting” section.

## Quick validation (small)

- `python -m py_compile kaggle_clicks/te.py kaggle_clicks/time_agg.py kaggle_clicks/run_baseline_te.py`
- `python -m kaggle_clicks.run_baseline_te --sample-parquet data/interim/train_sample_0p1pct.parquet --run-tag ram_smoke_default --n-estimators 30 --max-depth 4 --n-jobs 2`
- `python -m kaggle_clicks.run_baseline_te --sample-parquet data/interim/train_sample_0p1pct.parquet --run-tag ram_smoke_a4gap1_v2 --n-estimators 10 --max-depth 4 --n-jobs 2 --time-agg-windows 1 2 4 8 16 24 48 96 168 --time-agg-gap-hours 1`

## Next step

Re-run `A4_gap1_foldA` on the 10% sample (single run) to confirm the OOM is resolved; keep `--max-parallel-runs 1` and consider `--n-jobs 1..2` to reduce memory pressure.

